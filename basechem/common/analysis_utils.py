import json
import logging
import os
import pickle
import shutil
import subprocess
from shutil import copy, copyfile
from time import sleep

import numpy as np
from django.conf import settings
from django.core.mail import mail_admins
from rdkit import Chem
from rdkit.Chem import AllChem
from toklat.feature_generation import load_pdb_to_mol

from basechem.common.constants import *
from basechem.common.slurm_utils import (
    get_bash_script_from_commands,
    has_job_completed,
    has_job_stalled,
    run_on_slurm_node,
)
from basechem.main.constants import MAX_TORSION_ATTEMPTS
from basechem.mni_common.storage import media_file_exists, upload_to_media_storage

logger = logging.getLogger("django")


#####################
### TORSION UTILS ###
#####################


def get_torsion_commands(
    dihedral_smarts, dihedral_atoms, input_filename, output_filename, dihedral
):
    """
    Provides a list of bash commands to execute in order to run the Mayachemtools torsion script for a single dihedral.
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts used by mayachem to limit substructure search to relevant atoms
    :param input_filename: name of the input file provided to the Mayachemtools torsion script
    :param output_filename: name of the output file provided to the Mayachemtools torsion script
    :param dihedral: a number, the dihedral to calculate (between -180 and 180 degrees, inclusive)
    :return: a list of bash commands to run for the torsion scan
    """
    commands = [
        f'eval "$({settings.MAYACHEMTOOLS_CONDA_EXEC_PATH} shell.bash hook)"',
        f"conda activate {settings.MAYACHEMTOOLS_ENV}",
        f'Psi4PerformTorsionScan.py --infile3D yes --modeMols All --torsionMaxMatches 1 --torsionMinimize No --torsionRangeMode Angles --torsionRange {dihedral} --useChirality yes --method HF3c --overwrite -t "{dihedral_smarts}" --torsionsFilterbyAtomIndices {dihedral_atoms} -i {input_filename} -o {output_filename}',
    ]
    return commands


def get_psi4_log_filename(input_filename):
    """
    The torsion script from Mayachemtools writes Psi4 logs to a file that is named based on
    the input sdf filename. This function returns that name so that the log file can be located.
    :param input_filename: name of the input file provided to the Mayachemtools torsion script
    :return: Psi4 log filename generated by the mayachemtools torsion script.
    """
    return f"{os.path.splitext(input_filename)[0]}_Psi4.out"


def get_torsion_output_filenames(output_filename):
    """
    The torsion script from Mayachemtools modifies the output filename provided as
    the command line argument. This function returns those modified names.
    :param output_filename: name of the output file provided to the Mayachemtools torsion script
    :return: a tuple w/ names of output files (sdf filename, svg file name) saved on the EFS mount
        by the Mayachemtools torsion script
    """
    filename_prefix = os.path.splitext(output_filename)[0]
    # Psi4PerformTorsionScan.py from Mayachemtools appends "_Mol1_Torsion1_Match1" to the output filename
    # specified in the command line.
    return (
        f"{filename_prefix}_Mol1_Torsion1_Match1.sdf",
        f"{filename_prefix}_Mol1_Torsion1_Match1_Plot.svg",
    )


def set_up_slurm_shared_files(output_path):
    """
    Set up the slurm working directory in the basechem_tmp directory on in the shared files of
    the EFS mount and return paths to this working directory relative to the slurm node and basechem container.
    :param output_path: a string, the path (in the basechem container) to the final output file of the slurm analysis
    :returns: a tuple (slurm_working_dir, container_working_dir) where
        - slurm_working_dir is a string, the working directory relative to the slurm node
        - container_working_dir is a string, the working directory relative to the basechem container
    """
    path_to_create = os.path.dirname(os.path.relpath(output_path, settings.MEDIA_ROOT))
    slurm_working_dir = os.path.join(
        settings.SLURM_SHARED_FILES_TMP_DIR, path_to_create
    )
    container_working_dir = os.path.join(
        settings.SHARED_FILES_TMP_DIR_FROM_CONTAINER, path_to_create
    )
    os.makedirs(container_working_dir, exist_ok=True)
    return slurm_working_dir, container_working_dir


def run_mc_torsion_scan(
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Runs the torsion analysis either on Slurm or locally, depending on the settings.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if settings.SLURM_REST_API_HOST:
        return run_mc_torsion_scan_on_slurm(
            input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
        )
    else:
        return run_mc_torsion_scan_locally(
            input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
        )


def run_mc_torsion_scan_on_slurm(
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Checks if the output file already exists for the torsion scan and if not, runs
    the torsion analysis on a Slurm cluster.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if media_file_exists(output_path):
        return output_path

    all_dihedrals = range(-180, 190, 10)
    filenames = {}
    original_input_filename = os.path.basename(input_path)
    final_output_filename = os.path.basename(output_path)
    # Generate filenames for each dihedral
    for dihedral in all_dihedrals:
        filenames[dihedral] = {
            "input": f"{os.path.splitext(original_input_filename)[0]}_{dihedral}.sdf",
            "output": f"{os.path.splitext(final_output_filename)[0]}_{dihedral}.sdf",
        }
    # Set up the directory structure on the EFS mount
    slurm_working_dir, container_working_dir = set_up_slurm_shared_files(output_path)
    # Copy input files to working directory
    copyfile(input_path, os.path.join(container_working_dir, original_input_filename))
    # Make a copy of the input file for each dihedral because the Psi4 logfile name is based on the input file name
    for dihedral in all_dihedrals:
        copyfile(
            input_path,
            os.path.join(container_working_dir, filenames[dihedral]["input"]),
        )
    # Start all the jobs
    data = {}
    inprogress_dihedrals = []
    for dihedral in all_dihedrals:
        job_id = submit_torsion_job_to_slurm(
            f"{task_name}_{dihedral}",
            dihedral,
            dihedral_smarts,
            dihedral_atoms,
            filenames[dihedral]["input"],
            filenames[dihedral]["output"],
            slurm_working_dir,
        )
        if job_id:
            data[dihedral] = {"job_id": job_id, "attempt": 1}
            inprogress_dihedrals.append(dihedral)

    # Loop through jobs until all are complete. If a job fails, try again up to max_retries
    result_mols = []
    while inprogress_dihedrals:
        for dihedral in inprogress_dihedrals:
            if has_job_completed(data[dihedral]["job_id"]):
                job_name = f"{task_name}_{dihedral}"
                inprogress_dihedrals.remove(dihedral)
                try:
                    mol = process_torsion_job_result(
                        filenames[dihedral]["input"],
                        filenames[dihedral]["output"],
                        job_name,
                        container_working_dir,
                    )
                    result_mols.append(mol)
                except:
                    if data[dihedral]["attempt"] < MAX_TORSION_ATTEMPTS:
                        job_id = submit_torsion_job_to_slurm(
                            job_name,
                            dihedral,
                            dihedral_smarts,
                            dihedral_atoms,
                            filenames[dihedral]["input"],
                            filenames[dihedral]["output"],
                            slurm_working_dir,
                        )
                        if job_id:
                            data[dihedral]["job_id"] = job_id
                            data[dihedral]["attempt"] += 1
                            inprogress_dihedrals.append(dihedral)
            elif has_job_stalled(data[dihedral]["job_id"]):
                # Don't wait for this job - the admins have been notified
                inprogress_dihedrals.remove(dihedral)
        sleep(SLURM_JOB_STATUS_CHECK_PERIOD)

    # Calculate the relative energy based on the Psi4_Energy
    energies = [float(mol.GetProp("Psi4_Energy (kcal/mol)")) for mol in result_mols]
    min_energy = min(energies)
    for mol, energy in zip(result_mols, energies):
        mol.SetProp("Psi4_Relative_Energy (kcal/mol)", str(energy - min_energy))

    # Combine result files into a single file in EFS
    tmp_output_path = os.path.join(container_working_dir, final_output_filename)
    writer = Chem.SDWriter(tmp_output_path)
    for mol in result_mols:
        writer.write(mol)
    writer.close()
    # Copy the output file from the EFS mount to local
    copyfile(tmp_output_path, output_path)
    upload_to_media_storage(output_path)
    return output_path


def run_mc_torsion_scan_locally(  # pragma: no cover
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Checks if the output file already exists for the torsion scan and if not, runs
    the torsion analysis locally.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if media_file_exists(output_path):
        return output_path

    all_dihedrals = range(-180, 190, 10)
    filenames = {}
    original_input_filename = os.path.basename(input_path)
    final_output_filename = os.path.basename(output_path)
    # Generate filenames for each dihedral
    for dihedral in all_dihedrals:
        filenames[dihedral] = {
            "input": f"{os.path.splitext(original_input_filename)[0]}_{dihedral}.sdf",
            "output": f"{os.path.splitext(final_output_filename)[0]}_{dihedral}.sdf",
        }
    # Set up working directory
    tmp_output_path = os.path.join(
        os.path.dirname(output_path), "torsion_working_dir", final_output_filename
    )
    container_working_dir = os.path.dirname(tmp_output_path)
    os.makedirs(container_working_dir, exist_ok=True)
    # Copy input files to working directory
    copyfile(input_path, os.path.join(container_working_dir, original_input_filename))
    # Make a copy of the input file for each dihedral because the Psi4 logfile name is based on the input file name
    for dihedral in all_dihedrals:
        copyfile(
            input_path,
            os.path.join(container_working_dir, filenames[dihedral]["input"]),
        )
    result_mols = []
    for dihedral in all_dihedrals:
        try:
            # Run torsion job locally
            commands = get_torsion_commands(
                dihedral_smarts,
                dihedral_atoms,
                filenames[dihedral]["input"],
                filenames[dihedral]["output"],
                dihedral,
            )
            script = get_bash_script_from_commands(
                [f"export PATH=$PATH:{settings.MAYACHEMTOOLS_DIR}/bin"] + commands
            )
            tmp_script_file = os.path.join(
                container_working_dir, f"run_torsion_{dihedral}.sh"
            )
            with open(tmp_script_file, "w+") as script_file:
                script_file.write(script)
            subprocess.call(
                ["bash", tmp_script_file],
                cwd=container_working_dir,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.STDOUT,
            )
            # Process the output files from the torsion job
            mol = process_torsion_job_result(
                filenames[dihedral]["input"],
                filenames[dihedral]["output"],
                f"{task_name}_{dihedral}",
                container_working_dir,
            )
            result_mols.append(mol)
        except:
            pass

    # Calculate the relative energy based on the Psi4_Energy
    energies = [float(mol.GetProp("Psi4_Energy (kcal/mol)")) for mol in result_mols]
    min_energy = min(energies)
    for mol, energy in zip(result_mols, energies):
        mol.SetProp("Psi4_Relative_Energy (kcal/mol)", str(energy - min_energy))

    # Combine result files into a single file
    writer = Chem.SDWriter(tmp_output_path)
    for mol in result_mols:
        writer.write(mol)
    writer.close()
    # Copy the output file from the working dir to the expected location
    copyfile(tmp_output_path, output_path)
    upload_to_media_storage(output_path)
    return output_path


def process_torsion_job_result(
    input_filename, output_filename, job_name, container_working_dir
):
    """
    Process the output from a completed torsion job, returning a mol object if the job
    succeeded and raising an Exception if it failed.
    :param input_filename: a string, the name of the input file for the mayachem torsion script
    :param output_filename: a string, the name of the expected output file
    :param job_name: a string, the name of the job running on the slurm cluster
    :param container_working_dir: a string, the path to the working directory relative to the basechem container
    :returns: a mol object with the result of the torsion job
    """
    tmp_sdf_filename, tmp_svg_filename = get_torsion_output_filenames(output_filename)
    tmp_sdf_path = os.path.join(container_working_dir, tmp_sdf_filename)
    tmp_svg_path = os.path.join(container_working_dir, tmp_svg_filename)

    # The last step in the torsion scan produces a chart in the form of an svg file.
    # Look for that file to confirm that the job completed successfully.
    if not os.path.exists(tmp_svg_path):
        psi4_log_filename = get_psi4_log_filename(input_filename)
        psi4_log_filepath = os.path.join(
            os.path.dirname(tmp_sdf_path), psi4_log_filename
        )
        if os.path.exists(psi4_log_filepath):
            # Psi4 script failed for an unknown reason. In most cases, simply re-running this job
            # fixes the issue so an exception is raised here so that the Django Q fails and is
            # restarted automatically by the cluster.
            raise RuntimeError(f"Psi4 script failed for {job_name}")
        else:
            # An error unrelated to Psi4 occurred
            message = f"Torsion scan job {job_name} failed. Psi4 log file not found."
            logger.error(message)
            mail_admins(ADMIN_FAILURE, message)
            raise RuntimeError(f"Torsion failure, no Psi4 log file for {job_name}.")
    mol = Chem.SDMolSupplier(tmp_sdf_path)[0]
    return mol


def submit_torsion_job_to_slurm(
    job_name,
    dihedral,
    dihedral_smarts,
    dihedral_atoms,
    input_filename,
    output_filename,
    slurm_working_dir,
):
    """
    Submit a torsion job for a single dihedral to the slurm cluster.
    :param job_name: a string, the name of the job
    :param dihedral: an integer between -180 and 180 (inclusive), the dihedral to calculate
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
    :param input_filename: a string, the name of the input file to the mayachem torsion script
    :param output_filename: a string, the name of the expected output file
    :param slurm_working_dir: a string, the path to the working directory relative to the slurm node
    :returns: a number, the ID of the job running on the slurm cluster (if started successfully, else None)
    """
    # Start job
    commands = get_torsion_commands(
        dihedral_smarts, dihedral_atoms, input_filename, output_filename, dihedral
    )
    job_id = run_on_slurm_node(job_name, commands, slurm_working_dir)
    if job_id:
        logger.info(f"Started torsion analysis job on slurm: {job_name}")
    else:
        logger.error(f"Failed to submit torsion analysis task: {job_name}")
    return job_id


def collect_torsion_results(tasks):
    """
    Helper for constructing torsion results dictionary
    :return: a dictionary that maps each compound occurrence to its torsion scan results
    {co-pk: {
        "torsions": {
            "co-pk-dihedral": {
                "moltext": moltext,
                "rel_energy": rel_e,
                "torsion": torsion_dihedral }}
        "delta_energy": closest_dihedral_to_input_e,
        "initial_dihedral": initial_dihedral }}
    """
    results = {}
    for task in tasks:
        if not task.success:
            continue
        else:
            co_id = task.name.split("_")[1]
            results[f"co-{co_id}"] = task.result
    return results


############################
### TORSION ALERTS UTILS ###
############################


def get_torsion_alerts_commands(input_filepath, output_filepath):
    """
    Provides a list of bash commands to execute in order to run the Mayachemtools torsion alerts script.
    :param input_filepath: name of the input file provided to the Mayachemtools script
    :param output_filename: name of the output file provided to the Mayachemtools script
    :return: a list of bash commands to run to generate torsion alerts
    """
    input_filename = os.path.basename(input_filepath)
    output_filename = os.path.basename(output_filepath)
    commands = [
        f'RDKitFilterTorsionStrainEnergyAlerts.py --alertsTotalEnergyCutoff {TORSION_ALERTS_TOTAL_ENERGY_THRESHOLD} --mp yes --mpParams  "inputDataMode,lazy,numProcesses,4,chunkSize,8" -i {input_filename} -o {output_filename} --overwrite',
    ]
    return commands


def get_torsion_alerts_filepath(input_filepath, combined=True):
    """
    For a given input file to the torsion alerts Mayachemtools script, return the path to the expected output file
    :param input_filepath: a string, the path to the input file to `generate_torsion_alerts`
    :param combined: a boolean. If False, return the output path to pass to the Mayachemtools script (via the `-o` parameter).
        If True, return the path to the combined output file after processing the output files from the Mayachemtools script.
    :returns: a string, the output filepath
    """
    path, ext = os.path.splitext(input_filepath)
    if combined:
        return path + "_alerts_all" + ext
    else:
        return path + "_alerts" + ext


def generate_torsion_alerts(input_filepath):
    """
    Runs the Mayachemtools RDKitFilterTorsionStrainEnergyAlerts.py script on the given input file.
    :param input_filepath: a string, the path to the input sdf file -> should be /home/app/web/public/media/etc.
    :returns: a string, the path to the output file with torsion alerts
    """
    # The torsion alerts script returns two files. The "filtered" filepath has conformations
    # whose total torsion strain exceeds TORSION_ALERTS_TOTAL_ENERGY_THRESHOLD. The original
    # output filepath has conformations whose total torsion strain is less than the threshold.
    # We combine all conformations in a single file so we can return the results directly to
    # the basechem analysis calculating torsion alerts.
    expected_output_path = get_torsion_alerts_filepath(input_filepath, combined=False)
    path, ext = os.path.splitext(expected_output_path)
    filtered_output_path = path + "_Filtered" + ext
    combined_output_path = get_torsion_alerts_filepath(input_filepath)

    if os.path.exists(combined_output_path):
        return combined_output_path
    else:
        working_dir = os.path.dirname(input_filepath)
        commands = get_torsion_alerts_commands(input_filepath, expected_output_path)
        script = get_bash_script_from_commands(
            [f"export PATH=$PATH:{settings.MAYACHEMTOOLS_DIR}/bin"] + commands
        )
        tmp_script_file = os.path.join(working_dir, "run_torsion_alerts.sh")
        with open(tmp_script_file, "w+") as script_file:
            script_file.write(script)

        process = subprocess.run(["bash", tmp_script_file], cwd=working_dir)
        if process.returncode == 0:
            combine_sdf_files(
                combined_output_path, [expected_output_path, filtered_output_path]
            )
            return combined_output_path


def combine_sdf_files(combined_filepath, filepaths):
    """
    Combine multiple SDF files into a single file
    :param combined_filepath: a string, the filepath of the new combined sdf file
    :param filepaths: a list of strings, the filepaths of the existing sdf files
    """
    mols = []
    for filepath in filepaths:
        try:
            for mol in Chem.SDMolSupplier(filepath, removeHs=False):
                mols.append(mol)
        except:
            logger.info(
                f"Could not read mols from {filepath}. The file might be empty."
            )

    writer = Chem.SDWriter(combined_filepath)
    for mol in mols:
        writer.write(mol)
    writer.close()
    return combined_filepath


def mol_to_torsion_alerts(mol):
    """
    Given an rdkit mol, return a tuple of 1. torsion alert data that maps a pair of atom indices (ex: "6,7") to the energy of the torsion over that bond (ex: 5.9)
    if available (return an empty dictionary if there are no torsion alerts) and 2. the total energy score of the molecule
    :param mol: an rdkit mol object
    :return: a tuple of the torsion alert data and total energy
    """
    BONDS_INDEX = 0  # The index of "RotBondIndices" in TORSION_ALERTS_PROP
    ENERGY_INDEX = 3  # The index of "Energy" in TORSION_ALERTS_PROP
    NUM_VALUES = 12  # The number of properties in TORSION_ALERTS_PROP
    if not mol.HasProp(TORSION_ALERTS_PROP):
        alerts_dict = {}
    else:
        # Convert torsion_alerts from a space-delimited string to a list of lists, where each row is an alert for a different torsion
        torsion_alerts = mol.GetProp(TORSION_ALERTS_PROP).split(" ")
        torsion_alerts = [
            torsion_alerts[i : i + NUM_VALUES]
            for i in range(0, len(torsion_alerts), NUM_VALUES)
        ]
        alerts_dict = {
            torsion_alert[BONDS_INDEX]: torsion_alert[ENERGY_INDEX]
            for torsion_alert in torsion_alerts
        }

    if not mol.HasProp(TORSION_ALERTS_ENERGY_PROP):
        energy = ""
    elif mol.GetProp(TORSION_ALERTS_ENERGY_PROP) == "NA":
        energy = ""
    else:
        energy = "%.2f" % float(mol.GetProp(TORSION_ALERTS_ENERGY_PROP))
    return alerts_dict, energy


####################
### TOKLAT UTILS ###
####################


def generate_toklat_scores(pose_filepath, receptor_filepath):
    """
    Given an SDF file with docked poses and a receptor PDB file, run the Toklat scoring model
    to score each pose.
    :param pose_filepath: path to the SDF file with docked poses
    :param receptor_filepath: path to the receptor PDB file
    :return: a path to an SDF file with the given poses and their Toklat scores
    """
    output_filepath = f"{os.path.splitext(pose_filepath)[0]}_scored.sdf"
    if not os.path.exists(output_filepath):
        model = pickle.load(open(f"{settings.TOKLAT_DIR}/models/model_v0.pkl", "rb"))
        model.update_receptor(receptor_filepath)
        output_filepath = model.predict_and_interpret_sdf(
            pose_filepath, output_filepath, sort_by_score=True
        )
    return output_filepath


def mol_to_toklat_annotations(mol, receptor_pdb_path, interaction_scale=0.5):
    """
    Given a molecule with Toklat scores and features, and a receptor PDB, return a dictionary
    with annotations to add to the 3dmoljs viewer when viewing the molecule. This method is
    adapted from the `visualize_interpretation` method in "/opt/toklat/src/toklat/vis_utils.py",
    which is written for py3Dmol instead of 3dmoljs.
    :param mol: an rdkit mol object with Toklat features
    :param receptor_pdb_path: a string, the path to the receptor PDB file that this mol was docked to
    :param interaction_scale: scaling factor for the interaction lines.
    :return: a dictionary of the form {"cylinders": [], "spheres": []} where each cylinder represents
        interactions between ligand and receptor and each sphere represents an unsatisfied atom.
    """
    receptor_mol = load_pdb_to_mol(receptor_pdb_path)

    all_annotations = {"cylinders": [], "spheres": []}
    if mol.HasProp("toklat_top_interactions"):
        interactions = json.loads(mol.GetProp("toklat_top_interactions"))
        for interaction_dict in interactions:
            loc1 = mol.GetConformer().GetAtomPosition(interaction_dict["li"])
            loc2 = receptor_mol.GetConformer().GetAtomPosition(interaction_dict["pi"])
            val = interaction_dict["summed_interaction"]
            all_annotations["cylinders"].append(
                {
                    "start": dict(x=loc1.x, y=loc1.y, z=loc1.z),
                    "end": dict(x=loc2.x, y=loc2.y, z=loc2.z),
                    "color": "blue" if val < 0 else "red",
                    "radius": 0.15
                    * np.power(np.abs(val), 0.5)
                    / np.power(interaction_scale, 0.5),
                }
            )

    if mol.HasProp("toklat_unsatisfied_ligand_atoms"):
        atoms = json.loads(mol.GetProp("toklat_unsatisfied_ligand_atoms"))
        for atom_dict in atoms:
            loc = mol.GetConformer().GetAtomPosition(atom_dict["li"])
            all_annotations["spheres"].append(
                {"center": dict(x=loc.x, y=loc.y, z=loc.z)}
            )

    if mol.HasProp("toklat_unsatisfied_protein_atoms"):
        atoms = json.loads(mol.GetProp("toklat_unsatisfied_protein_atoms"))
        for atom_dict in atoms:
            loc = receptor_mol.GetConformer().GetAtomPosition(atom_dict["pi"])
            all_annotations["spheres"].append(
                {"center": dict(x=loc.x, y=loc.y, z=loc.z)}
            )
    return all_annotations


#################
### ESP UTILS ###
#################


def run_esp_predict(input_directory, molecule_type="ligand"):
    """
    Runs ESP-DNN predict from the correct directory for the files in the given directory
    :param input_directory: directory with ESP-DNN compounds to predict
    :param molecule_type: 'ligand' or 'protein'
    :return: True if process returned a zero code
    """
    cmd = [
        "/root/miniconda3/envs/esp-dnn-env/bin/python",
        "-m",
        "esp_dnn.predict",
        "-m",
        molecule_type,
        "-i",
        input_directory,
    ]

    process = subprocess.run(cmd, cwd=settings.ESP_DIR)
    if process.returncode == 0:
        return True


def run_apbs(pqr_filepath):
    """
    Run APBS on the given PQR file to generate ESP map data
    :param pqr_filepath: path to an input PQR file with a single ligand. Basechem uses ESP DNN to generate PQR files.
    :return: path to the output DX file with ESP map data, if successful
    """
    working_dir = os.path.dirname(pqr_filepath)
    config_filepath = f"{os.path.splitext(pqr_filepath)[0]}_apbs.in"
    output_filepath = f"{os.path.splitext(pqr_filepath)[0]}_apbs.dx"
    config_text = f"""
read
    mol pqr "{os.path.basename(pqr_filepath)}"
end
elec
    mg-auto
    mol 1

    fgcent mol 1    # fine grid center
    cgcent mol 1    # coarse grid center
    fglen 12 12 12
    cglen 24 24 24
    dime 65 65 65
    lpbe          # l=linear, n=non-linear Poisson-Boltzmann equation
    bcfl sdh      # "Single Debye-Hueckel" boundary condition
    pdie 2.0      # protein dielectric
    sdie 78.0     # solvent dielectric
    chgm spl2     # Cubic B-spline discretization of point charges on grid
    srfm smol     # smoothed surface for dielectric and ion-accessibility coefficients
    swin 0.3
    temp 310.0    # temperature
    sdens 10.0
    calcenergy no
    calcforce no
    srad 1.4

    ion charge +1 conc 0.15 radius 2.0
    ion charge -1 conc 0.15 radius 1.8

    write pot dx "{os.path.splitext(os.path.basename(output_filepath))[0]}"
end
quit
        """
    with open(config_filepath, "w") as f:
        f.write(config_text)
    cmd = ["apbs", config_filepath]
    process = subprocess.run(cmd, cwd=working_dir)
    if process.returncode == 0:
        return output_filepath


def collect_esp_results(tasks):
    """
    Helper for constructing ESP results dictionary
    :return: a dictionary that maps each parent and compound to its esp data
        {"compounds": {co-pk: {"pqr": esp_pqr, "dx": esp_dx, "related_series": "s-(pk of series)"}},
        "references": {s-pk: esp_pqr},
        "receptors": {s-pk: esp_pqr}}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            # All the references are returned together
            results["references"] = task.result["references"]
            results["receptors"] = task.result.get("receptors", {})
        else:
            # Each compound occurrence runs in its own task
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


###################
### ALIGN UTILS ###
###################


def collect_align_results(tasks):
    """
    Helper for constructing align results dictionary
    :return: a dictionary that maps each parent and compound to its aligned conf(s)
        {"compounds": {co-pk: {conf-id:  {"moltext": conf_moltext, "r_mmff_rel_energy": str}}},
        "references": {s-pk: moltext}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            results["references"] = task.result["references"]
            results["receptors"] = task.result["receptors"]
        else:
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


#######################
### RDOCK CONSTANTS ###
#######################
# These might be updated to be more dynamic later as we see how rDock works
# with generic settings for each project
RADIUS = 6.0
SMSPH = 1.0
MINVOL = 100
MAXCAV = 1
VINC = 0.0
GRIDSTEP = 0.5

TR_MODE = "FREE"
RO_MODE = "FREE"
DI_MODE = "FREE"
DI_MAX = 30.0

###################
### RDOCK UTILS ###
###################


def collect_dock_results(tasks):
    """
    Helper for constructing dock results dictionary
    :return: a dictionary that maps each parent and compound to its aligned conf(s)
        {"compounds": {co-pk: {conf-id:  {"moltext": conf_moltext, "dockingScore": str}}},
        "references": {s-pk: moltext}}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            results["references"] = task.result["references"]
            results["receptors"] = task.result["receptors"]
        else:
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


def generate_rdock_system_prm(mol2, reflig, prefix):
    """
    Create an rdock parameter file for the given receptor and reference ligand
    Parameter defaults are set with guidance from Andy Jennings Consulting, LLC
    :param mol2: path to mol2 file of the receptor to use for rdock
    :param reflig: path to sdf file to use as the reference ligand for rdock
    :param prefix: prefix to use for the rdock output files - generally a series name
    :return: path to rdock parameter file
    """
    reference_dir = os.path.split(mol2)[0]
    prm_path = os.path.join(reference_dir, f"{prefix}_rdock.prm")

    text = f"""RBT_PARAMETER_FILE_V1.00
TITLE {prefix}_auto_setup

RECEPTOR_FILE {mol2}
RECEPTOR_FLEX 3.0

##############################################
# CAVITY DEFINITION: REFERENCE LIGAND METHOD #
##############################################
SECTION MAPPER
    SITE_MAPPER RbtLigandSiteMapper
    REF_MOL {reflig}
    RADIUS {RADIUS}
    SMALL_SPHERE {SMSPH}
    MIN_VOLUME {MINVOL}
    MAX_CAVITIES {MAXCAV}
    VOL_INCR {VINC}
    GRIDSTEP {GRIDSTEP}
END_SECTION

############################
# CAVITY RESTRAINT PENALTY #
############################
SECTION CAVITY
    SCORING_FUNCTION RbtCavityGridSF
    WEIGHT 1.0
END_SECTION
    """

    with open(prm_path, "w") as f:
        f.write(text)
    f.close()

    return prm_path


def generate_rdock_grid(rdock_prm_file):
    """
    Generates a .grd and .as file in the same directory as the `rdock_prm_file` file
    :param rdock_prm_file: path to rdock parameter file that will be used to create the grid
    :return: True if there was no error when generating the rDock files
    """
    cmd = ["rbcavity", "-was", "-d", "-r", rdock_prm_file]
    process = subprocess.run(args=cmd, stdout=subprocess.PIPE)

    if "Error" in str(process.stdout):
        logger.error(f"rDock grid generation failed for prm file: {rdock_prm_file}")
        message = f"rDock failed for {rdock_prm_file} because the cavity file failed to generate."
        mail_admins(ADMIN_FAILURE, message)
        return False

    if "Segmentation fault" in str(process.stdout):
        message = f"rDock failed for {rdock_prm_file}. Check the Series sdf does not have very long lines."
        mail_admins(ADMIN_FAILURE, message)
        return False
    return True


def copy_rdock_ligand_prm(new_path):
    """
    Copy rdock prm file from installation to given path
    Additional parameter defaults are set with guidance from Andy Jennings Consulting, LLC
    :param new_path: path to copy the default rdock.prm file to
    """
    copy("/opt/rDock_2022_src/data/scripts/dock.prm", new_path)

    with open(new_path, "a+") as f:
        f.write("\n")
        f.write("SECTION LIGAND\n")
        f.write("\tTRANS_MODE\t%s\n" % TR_MODE)
        f.write("\tROT_MODE\t%s\n" % RO_MODE)
        f.write("\tDIHEDRAL\t%s\n" % DI_MODE)
        f.write("\tMAX_TRANS\t1.0\n")
        f.write("\tMAX_ROT\t30.0\n")
        f.write("\tMAX_DIHEDRAL\t%.1f\n" % DI_MAX)
        f.write("END_SECTION\n")


def run_rdock(ligand_filepath, output_filepath, receptor_prm, ligand_prm, ligruns=5):
    """
    Runs rDock docking for the given ligand and returns path to sdf of poses
    :param ligand_filepath: sdf file with ligand(s) to dock - ex. conformers of one VSM
    :param output_filepath: filepath to save docking results to
    :param receptor_prm: parameter file for defining the system of the receptor to dock to
    :param ligand_prm: parameter file for the docking protocol for this job
    :param ligruns: number of poses to produce for each conformation
    :return: path to sdf file with docked poses
    """
    basename = os.path.splitext(output_filepath)[0]
    cmd = [
        "rbdock",
        "-i",
        ligand_filepath,
        "-o",
        basename,
        "-r",
        receptor_prm,
        "-p",
        ligand_prm,
        "-n",
        str(ligruns),
    ]

    process = subprocess.run(args=cmd, stdout=subprocess.PIPE)

    if process.returncode != 0:
        logger.error(
            f"rDock failed for receptor - {receptor_prm} with ligand input file - {ligand_filepath}. CMD = {cmd}."
        )
        return ""

    return output_filepath


###################
### MMP UTILS ###
###################
def collect_mmp_results(tasks):
    """
    Helper for constructing MMP results dictionary
    :return: a dictionary that maps each compound occurrence to its MMP analysis results
    {co-pk: list_of_Compound_PKs}
    """
    results = {}
    for task in tasks:
        if not task.success:
            continue
        else:
            co_id = task.name.split("_")[1]
            results[f"co-{co_id}"] = task.result
    return results


###################
### ALIGN UTILS ###
###################
def convert_sdf_to_mol2(sdf_filepath):
    """
    RDKit doesn't support conversion to mol2 format, so we use OpenBabel to convert the sdf to mol2
    :param sdf_filepath: path to sdf file to convert
    :return: path to mol2 file
    """
    mol2_filepath = os.path.splitext(sdf_filepath)[0] + ".mol2"
    cmd = ["obabel", "-i", "sdf", sdf_filepath, "-O", mol2_filepath]

    process = subprocess.run(args=cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if process.returncode == 0:
        return mol2_filepath


def run_lsalign(query_sdf, template_sdf, final_sdf_path):
    """
    Flexibly align the structures in the query sdf to the template compound and return the best aligned structure
    :param query_sdf: sdf file containing structures (ideally conformers) to align to the template
    :param template_sdf: sdf file containing a single structure to align to
    :param final_sdf_path: path to write the sdf file containing the single best aligned structure
    :return: path to sdf file containing single best aligned structure
    """
    if os.path.exists(final_sdf_path):
        return final_sdf_path

    template_mol2 = convert_sdf_to_mol2(template_sdf)
    lsalign_dir = os.path.join(os.path.dirname(query_sdf), "lsalign")
    os.makedirs(lsalign_dir, exist_ok=True)

    query_confs = [conf for conf in Chem.SDMolSupplier(query_sdf)]
    aligned_confs = []

    for i, conf in enumerate(query_confs):
        # Write each conformer to it's own file
        conf_sdf = os.path.join(lsalign_dir, f"conf_{i}.sdf")
        writer = Chem.SDWriter(conf_sdf)
        writer.write(conf)
        writer.close()
        conf_mol2 = convert_sdf_to_mol2(conf_sdf)
        aligned_pdb = os.path.join(lsalign_dir, f"aligned_conf_{i}.pdb")

        cmd = [
            "/opt/LS-align/src/LSalign",
            conf_mol2,
            template_mol2,
            "-rf",
            "1",  # flexible align
            "-md",
            "1",  # generate rotamers of query ligand
            "-acc",
            "1",  # take longer to search for more accurate alignment
            "-o",
            aligned_pdb,
        ]

        process = subprocess.run(
            args=cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE
        )

        try:
            if not process.stderr:
                # LS-Align outputs a bytes table which needs to be parsed to get the PC-Score
                result_values = process.stdout.split(b"\n")[3]
                pc_score = [x for x in result_values.split(b" ") if x][5].decode(
                    "utf-8"
                )

                # Remove second mol (template structure) from pdb, RDKit struggles to parse with GetMolFrags
                with open(aligned_pdb, "r") as input:
                    with open("/tmp/tmp.pdb", "w") as output:
                        lines = input.readlines()
                        for line in lines:
                            if "TER" in line:
                                break
                            else:
                                output.write(line)
                shutil.move("/tmp/tmp.pdb", aligned_pdb)

                pdb = Chem.MolFromPDBFile(aligned_pdb, sanitize=False, removeHs=False)
                # If there is anything else in the file, only keep the first mol
                mol = Chem.GetMolFrags(pdb, asMols=True)[0]
                mol.SetProp("LSAlign_PCScore", pc_score)
                # Reassign all props since they get removed by LS-Align
                mol.SetProp("_Name", conf.GetProp("_Name"))
                for prop in conf.GetPropNames():
                    mol.SetProp(prop, conf.GetProp(prop))
                # ls-align removes bond order so need to reset the aromaticity, etc from the original query conformer
                mol = AllChem.AssignBondOrdersFromTemplate(conf, mol)
                aligned_confs.append(mol)
            else:
                mail_admins(
                    ADMIN_FAILURE,
                    f"LS-Align failed for {conf_mol2} and {template_mol2}: \n{process.stderr}",
                )
        except:
            # Sometimes there is a weird error where a pdb file doesn't exist
            continue

    sorted_confs = sorted(
        aligned_confs, key=lambda x: float(x.GetProp("LSAlign_PCScore")), reverse=True
    )
    final_mol = Chem.AddHs(sorted_confs[0], addCoords=True)
    writer = Chem.SDWriter(final_sdf_path)
    writer.write(final_mol)
    writer.close()

    # Delete intermediary files
    shutil.rmtree(lsalign_dir)

    return final_sdf_path
